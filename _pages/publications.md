---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

## 2024
---
- *Can Frozen Large Language Models Solve Visual Reasoning?* \
**Tian Yun**, Ellie Pavlick, Chen Sun \
Under Review

- *$100K or 100 days: Trade-offs when Pre-Training with Academic Resources*
Apoorv Khandelwal, **Tian Yun**, Nihal V. Nayak, Jack Merullo, Stephen H. Bach, Chen Sun, Ellie Pavlick \
Under Review \
[[paper](https://arxiv.org/abs/2410.23261)] [[code](https://github.com/apoorvkh/academic-pretraining)]

- *mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?*
Tianze Hua\*, **Tian Yun**\*, Ellie Pavlick \
NAACL 2024 \
[[paper](https://arxiv.org/abs/2404.12444)] [[project](https://multilingual-othello.github.io/)] [[code](https://github.com/ethahtz/multilingual_othello)]

## 2023
---
- *Emergence of Grounded Representations in Embodied Sequence Modeling*  
**Tian Yun**\*, Zilai Zeng\*, Kunal Handa, Ashish Thapliyal, Bo Pang, Ellie Pavlick, Chen Sun \
EMNLP 2023 \
[[paper](https://arxiv.org/abs/2311.02171)] [[project](https://abstract-state-seqmodel.github.io/)] [[code](https://github.com/brown-palm/abstract-state-seqmodel)]

- *Improved Inference of Human Intent by Combining Plan Recognition and Language Feedback*  
Ifrah Idrees, **Tian Yun**, Naveen Sharma, Nakul Gopalan, Stefanie Tellex, George Konidaris \
IROS 2023 \
[[paper](https://arxiv.org/abs/2310.02462)]

- *Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?*  
**Tian Yun**, Usha Bhalla, Ellie Pavlick, Chen Sun \
TMLR \
[[paper](https://arxiv.org/abs/2203.17271)] [[project](https://vlm-primitive-concepts.github.io)] [[code](https://github.com/tttyuntian/vlm_primitive_concepts)]

## 2021
---
- *Does Vision-and-Language Pretraining Improve Lexical Grounding?*  
**Tian Yun**, Chen Sun, Ellie Pavlick \
Findings of EMNLP 2021 \
[[paper](https://aclanthology.org/2021.findings-emnlp.370.pdf)] [[code](https://github.com/tttyuntian/vlm_lexical_grounding)]

- *Mining Biomedical Texts for Pediatric Information*  
**Tian Yun**, Deepti Garg, Natalia Khuri \
14th International Joint Conference on Biomedical Engineering Systems and Technologies - BIOINFORMATICS, 2021 \
[[paper](https://www.scitepress.org/Papers/2021/103102/103102.pdf)] 

# Preprints
---
- *BLOOM: A 176B-Parameter Open-Access Multilingual Language Model*  
Teven Scao et al. \
arXiv preprint arXiv:2211.05100 (2022) \
[[paper](https://arxiv.org/abs/2211.05100)]


<!---
# 2022
---
- <font size="5"> Do Vision-Language Pretrained Models Learn Primitive Concepts? </font>  
**Tian Yun**, Usha Bhalla, Ellie Pavlick, Chen Sun. \
Submitted to CVPR 2022.  

# 2021
---
- <font size="5"> Does Vision-and-Language Pretraining Improve Lexical Grounding? </font>  
**Tian Yun**, Chen Sun, Ellie Pavlick. \
Findings of EMNLP, 2021. \
[[paper](https://aclanthology.org/2021.findings-emnlp.370.pdf)] [[code](https://github.com/tttyuntian/vlm_lexical_grounding)]

- <font size="5"> Mining Biomedical Texts for Pediatric Information. </font>  
**Tian Yun**, Deepti Garg, Natalia Khuri. \
14th International Joint Conference on Biomedical Engineering Systems and Technologies - BIOINFORMATICS, 2021. \
[[paper](https://www.scitepress.org/Papers/2021/103102/103102.pdf)] 
-->
<!---
{% if author.googlescholar %}
  You can also find my articles on <u><a href="#{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}
-->
